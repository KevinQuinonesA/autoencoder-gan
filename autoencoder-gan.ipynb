{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinQuinonesA/autoencoder-gan/blob/main/autoencoder-gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OnFTM8maZzN2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGLvsCLtbk4s",
        "outputId": "d71a4edc-824a-4737-f3c3-36c10630f303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:  999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb71132b290>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999 # 42\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7NfR5VCc3V0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfb0323-5c67-4581-8980-cd90f5a042f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-hfPf5AucUwD"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "\n",
        "# train_dataroot = \"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/train\"\n",
        "# test_dataroot  = \"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/test\"\n",
        "# val_dataroot = \"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/val\"\n",
        "# checkpoints_folder = \"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/checkpoints\"\n",
        "\n",
        "train_dataroot = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/output3/train\"\n",
        "test_dataroot = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/output3/test\"\n",
        "val_dataroot = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/output3/val\"\n",
        "checkpoints_folder = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/checkpoints\"\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers    = 2      # 4 # 8\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 32     # 8 (en caso que las im√°genes sean muy pesadas or ERROR: CUDA OUT OF MEMORY)\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 128\n",
        "\n",
        "# Number of channels in the training images. \n",
        "nc = 1\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 16   # 100 # 256\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs \n",
        "num_epochs = 101 # 300\n",
        "\n",
        "# Number of training epochs \n",
        "step = (num_epochs - 1) / 5 \n",
        "\n",
        "# Learning rate for optimizers ------ Optimizar\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5 #(0.9, 0.999)\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "\n",
        "#are we going to do training?\n",
        "training = False\n",
        "\n",
        "#are we going to do testing?\n",
        "testing = True\n",
        "\n",
        "comparation = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lyDp4TiPxvTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "393bda0e-938b-4fff-e50f-21e5d034ed69"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9115beafe16f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train_dataset = dset.ImageFolder(root=train_dataroot,\n\u001b[0m\u001b[1;32m      5\u001b[0m                            transform=transforms.Compose([\n\u001b[1;32m      6\u001b[0m                                \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/train'"
          ]
        }
      ],
      "source": [
        "## We can use an image folder dataset the way we have it setup.\n",
        "# Create the dataset\n",
        "\n",
        "train_dataset = dset.ImageFolder(root=train_dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.Grayscale(num_output_channels=1),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.5], [0.5]),\n",
        "                           ]))\n",
        "\n",
        "test_dataset = dset.ImageFolder(root=test_dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.Grayscale(num_output_channels=1),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.5], [0.5]),\n",
        "                           ]))\n",
        "\n",
        "val_dataset = dset.ImageFolder(root=val_dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.Grayscale(num_output_channels=1),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize([0.5], [0.5]),\n",
        "                           ]))\n",
        "\n",
        "# Create the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(train_loader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miM7ReQFyhr1"
      },
      "outputs": [],
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1: #Conv2d\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1: # BatchNorm2d\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "         \n",
        "        # Building an linear encoder with Linear\n",
        "        # layer followed by Relu activation function\n",
        "        # 784 ==> 9\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            nn.Conv2d(1, 16 , 3, stride=2, padding =1), #N, 2, 64, 64\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32 , 3, stride=2, padding =1), #N, 4, 32, 32\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64 , 3, stride=2, padding =1), #N, 8, 16, 16\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128 , 3, stride=2, padding =1), #N, 16, 8, 8\n",
        "           \n",
        "        )\n",
        "         \n",
        "        # Building an linear decoder with Linear\n",
        "        # layer followed by Relu activation function\n",
        "        # The Sigmoid activation function\n",
        "        # outputs the value between 0 and 1\n",
        "        # 9 ==> 784\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            \n",
        "          \n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # N, 8, 16, 16\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),  # N, 4, 32, 32\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # N, 2, 64, 64\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),  # N, 1, 128, 128\n",
        "        )\n",
        " \n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        image_re = self.decoder(latent)\n",
        "        return image_re\n"
      ],
      "metadata": {
        "id": "Irzt50dUMU5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "105z2vNey-iq"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 128 x 128\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 64 x 64\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf*2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 16 x 16\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "          )          \n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "        self.last_layer = nn.Sequential(\n",
        "            nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.main(input)\n",
        "        out = self.last_layer(x)\n",
        "        return x, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdXi0OePzCQE"
      },
      "outputs": [],
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Print the model\n",
        "print(netD)\n",
        "\n",
        "# Create the generator/AUTOENCODER\n",
        "netG = Autoencoder().to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Print the model\n",
        "print(netG)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the weights_init function to randomly initialize all weights\n",
        "#  to mean=0, stdev=0.2.\n",
        "netD.apply(weights_init)"
      ],
      "metadata": {
        "id": "tUXdprcojHaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywBrrSYhzJs_"
      },
      "outputs": [],
      "source": [
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "loss_function = torch.nn.MSELoss()\n",
        "loss_function_penalty  = torch.nn.MSELoss()\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Using an Adam Optimizer with lr = 0.1\n",
        "optimizerG = torch.optim.Adam(netG.parameters(),\n",
        "                             lr = 1e-1,\n",
        "                             weight_decay = 1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if(training): \n",
        "  # Training Loop\n",
        "\n",
        "  # Lists to keep track of progress\n",
        "  img_list = []\n",
        "  G_losses = []\n",
        "  D_losses = []\n",
        "\n",
        "  img_list_val = []\n",
        "  G_losses_val = []\n",
        "  D_losses_val = []\n",
        "\n",
        "  iters = 0\n",
        "\n",
        "  print(\"Starting Training Loop...\")\n",
        "  # For each epoch\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      loss_total_disc = 0\n",
        "      # For each batch in the dataloader\n",
        "      netD.train()\n",
        "      netG.train()\n",
        "      for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "          \n",
        "          real_cpu = data[0].to(device)\n",
        "          # Generate fake image batch with G\n",
        "          netG.zero_grad()\n",
        "          fake = netG(real_cpu)\n",
        "          output_fake_g, f2 = netD(fake)\n",
        "          output_real_g, f1 = netD(real_cpu)\n",
        "          \n",
        "        \n",
        "          loss_g = loss_function(fake, real_cpu) + loss_function_penalty(output_fake_g, output_real_g)\n",
        "          \n",
        "          # Classify all fake batch with D\n",
        "          loss_g.backward()\n",
        "          optimizerG.step()\n",
        "        \n",
        "\n",
        "  \n",
        "          #DISCRIMINADOR\n",
        "          netD.zero_grad()\n",
        "          x1,output_fake = netD(fake.detach())\n",
        "          x2,output_real = netD(real_cpu.detach())\n",
        "\n",
        "          #LABELS\n",
        "          b_size = real_cpu.size(0)\n",
        "          label_real = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "          label_fake = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
        "          # Calculate D's loss on the all-fake batch\n",
        "          loss_fake = criterion(output_fake.view(-1), label_fake)\n",
        "          loss_real = criterion(output_real.view(-1), label_real)\n",
        "          loss_dic_tr = (loss_fake + loss_real)*0.5\n",
        "          loss_total_disc += loss_dic_tr.item()\n",
        "\n",
        "          loss_dic_tr.backward()\n",
        "          optimizerD.step()\n",
        "          #label.fill_(fake_label)\n",
        "          \n",
        "          D_x = output_real.mean().item()\n",
        "          D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "          # Reinit the affine network weights\n",
        "          if loss_dic_tr.item() < 1e-5:  # >\n",
        "            netD.apply(weights_init)\n",
        "            print(\"Reloading discriminator weights\")\n",
        "\n",
        "          # Output training stats\n",
        "          if i % 50 == 0:\n",
        "              print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                    % (epoch, num_epochs, i, len(train_loader),\n",
        "                      loss_dic_tr.item(), loss_g.item(), D_x, D_G_z1, D_G_z1))\n",
        "\n",
        "          # Save Losses for plotting later\n",
        "          G_losses.append(loss_g.item())\n",
        "          D_losses.append(loss_dic_tr.item())\n",
        "\n",
        "          # Check how the generator is doing by saving G's output on fixed_noise\n",
        "          if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
        "              with torch.no_grad():\n",
        "                  fake = netG(real_cpu).detach().cpu()\n",
        "              img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "          iters += 1\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        netG.eval()\n",
        "        netD.eval()\n",
        "        loss_total_disc = 0\n",
        "\n",
        "        # For each batch in the dataloader\n",
        "        for i, data in enumerate(valid_loader, 0):\n",
        "            \n",
        "            real_cpu = data[0].to(device)\n",
        "            # Generate fake image batch with G\n",
        "            fake = netG(real_cpu)\n",
        "            output_fake_g, f2 = netD(fake)\n",
        "            output_real_g, f1 = netD(real_cpu)\n",
        "            \n",
        "          \n",
        "            loss_g = loss_function(fake, real_cpu) + loss_function_penalty(output_fake_g, output_real_g)\n",
        "            \n",
        "            # Classify all fake batch with D\n",
        "\n",
        "    \n",
        "            #DISCRIMINADOR\n",
        "            x1,output_fake = netD(fake.detach())\n",
        "            x2,output_real = netD(real_cpu.detach())\n",
        "\n",
        "            #LABELS\n",
        "            b_size = real_cpu.size(0)\n",
        "            label_real = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "            label_fake = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
        "            # Calculate D's loss on the all-fake batch\n",
        "            loss_fake = criterion(output_fake.view(-1), label_fake)\n",
        "            loss_real = criterion(output_real.view(-1), label_real)\n",
        "            loss_dic_tr = (loss_fake + loss_real)*0.5\n",
        "            loss_total_disc += loss_dic_tr.item()\n",
        "\n",
        "            #label.fill_(fake_label)\n",
        "            \n",
        "            D_x = output_real.mean().item()\n",
        "            D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "\n",
        "            # Output training stats\n",
        "            if i % 50 == 0:\n",
        "                print('[%d/%d][%d/%d]\\t Validation Loss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                      % (epoch, num_epochs, i, len(valid_loader),\n",
        "                        loss_dic_tr.item(), loss_g.item(), D_x, D_G_z1, D_G_z1))\n",
        "\n",
        "            # Save Losses for plotting later\n",
        "            G_losses_val.append(loss_g.item())\n",
        "            D_losses_val.append(loss_dic_tr.item())\n",
        "\n",
        "            # Check how the generator is doing by saving G's output on fixed_noise\n",
        "            if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(valid_loader)-1)):\n",
        "                with torch.no_grad():\n",
        "                    fake = netG(real_cpu).detach().cpu()\n",
        "                img_list_val.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "            iters += 1\n",
        "\n",
        "      # Save checkpoints\n",
        "      if epoch % 5 == 0:\n",
        "          name_gen = 'GenModel_' + str(epoch) + '.pth'\n",
        "          name_dis = 'DisModel_' + str(epoch) + '.pth'\n",
        "          torch.save(netG.state_dict(), os.path.join(checkpoints_folder, name_gen))\n",
        "          torch.save(netD.state_dict(), os.path.join(checkpoints_folder, name_dis))\n",
        "          print('Saving model')"
      ],
      "metadata": {
        "id": "9dALWWtY9xxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if training: \n",
        "  print(f'NUMERO DE FAKES{img_list}')"
      ],
      "metadata": {
        "id": "mqqCbG3l9yIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXs9mL5W9yIu"
      },
      "outputs": [],
      "source": [
        "if training: \n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "  plt.plot(G_losses,label=\"G\")\n",
        "  plt.plot(D_losses,label=\"D\")\n",
        "  plt.plot(G_losses_val,label=\"GV\")\n",
        "  plt.plot(D_losses_val,label=\"DV\")\n",
        "  plt.xlabel(\"iterations\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI-YiYHP9yIu"
      },
      "outputs": [],
      "source": [
        "if training: \n",
        "  #%%capture\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  plt.axis(\"off\")\n",
        "  ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "  ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "  HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHdZVSL_-aoN"
      },
      "outputs": [],
      "source": [
        "if training: \n",
        "  #Validation\n",
        "  #%%capture\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  plt.axis(\"off\")\n",
        "  ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list_val]\n",
        "  ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "  HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbpKQvzG-nQz"
      },
      "outputs": [],
      "source": [
        "if training: \n",
        "  # Grab a batch of real images from the dataloader\n",
        "  real_batch = next(iter(train_loader))\n",
        "\n",
        "  # Plot the real images\n",
        "  plt.figure(figsize=(15,15))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Real Images\")\n",
        "  plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "  # Plot the fake images from the last epoch\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Fake Images\")\n",
        "  plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoLhuntw9yIv"
      },
      "outputs": [],
      "source": [
        "if training: \n",
        "  # Grab a batch of real images from the dataloader\n",
        "  real_batch = next(iter(valid_loader))\n",
        "\n",
        "  # Plot the real images\n",
        "  plt.figure(figsize=(15,15))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Real Images\")\n",
        "  plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "  # Plot the fake images from the last epoch\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Fake Images\")\n",
        "  plt.imshow(np.transpose(img_list_val[-1],(1,2,0)))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2JVlacy9yIv"
      },
      "outputs": [],
      "source": [
        "# from skimage import io\n",
        "\n",
        "\n",
        "# image=io.imread(\"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/images/test.png\")/255.0 # imread lee las imagenes con los pixeles codificados como enteros \n",
        "# # en el rango 0-255. Por eso la convertimos a flotante y en el rango 0-1\n",
        "\n",
        "# print(\"- Dimensiones de la imagen:\")\n",
        "# print(image.shape)\n",
        "\n",
        "# plt.imshow(image,vmin=0,vmax=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM__aG-H9yIw"
      },
      "outputs": [],
      "source": [
        "if training:\n",
        "  # Grab a batch of real images from the dataloader\n",
        "  real_batch = next(iter(train_loader))\n",
        "\n",
        "  # Plot the fake images from the last epoch\n",
        "  plt.figure(figsize=(30,30))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"Fake Images\")\n",
        "  plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "  plt.show()\n",
        "  print(np.transpose(img_list[-1],(1,2,0)).size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ELIMINAR ARCHIVOS DENTRO DE LA CARPETA SALIDAS\n",
        "import os\n",
        "import shutil\n",
        "# Elimina los archivos de la carpeta\n",
        "# output_path_r = \"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/salidas/real\"\n",
        "# output_path_g = \"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/salidas/generate\"\n",
        "\n",
        "output_path_r = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/salidas/real\"\n",
        "output_path_g = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/salidas/generate\"\n",
        "\n",
        "for filename in os.listdir(output_path_r):\n",
        "    file_path = os.path.join(output_path_r, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar {file_path}: {e}')\n",
        "\n",
        "for filename in os.listdir(output_path_g):\n",
        "    file_path = os.path.join(output_path_g, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print(f'Error al eliminar {file_path}: {e}')\n",
        "  \n"
      ],
      "metadata": {
        "id": "MRayF4q57hhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if testing and comparation:\n",
        "if testing:\n",
        "  img_list_test = []\n",
        "\n",
        "  #name_gen = 'GenModel_'+ str(num_epochs -1 ) +'.pth'\n",
        "  #name_dis = 'DisModel_'+ str(num_epochs -1 ) +'.pth'\n",
        "  name_gen = 'GenModel_'+ str(15) +'.pth'\n",
        "  name_dis = 'DisModel_'+ str(15) +'.pth'\n",
        "  # Cargar los par√°metros de la red neuronal\n",
        "\n",
        "  #output_path = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/salidas\"\n",
        "  \n",
        "  output_path_real = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/salidas/real\"\n",
        "  output_path_generate = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/salidas/generate\"\n",
        "\n",
        "  netG.load_state_dict(torch.load(os.path.join(checkpoints_folder, name_gen)))\n",
        "  netD.load_state_dict(torch.load(os.path.join(checkpoints_folder, name_dis)))\n",
        "\n",
        "  # Evaluar el modelo en el conjunto de datos de prueba\n",
        "  netG.eval()\n",
        "  netD.eval()\n",
        "\n",
        "  correctos = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      \n",
        "        loss_total_disc = 0\n",
        "\n",
        "        # For each batch in the dataloader\n",
        "        for i, data in enumerate(test_loader, 0):\n",
        "            \n",
        "            real_cpu = data[0].to(device)\n",
        "\n",
        "            for j in range(real_cpu.size(0)):\n",
        "              # Save the real image\n",
        "              img_name_real = \"real_image_{}.png\".format(i*test_loader.batch_size + j)\n",
        "              vutils.save_image(real_cpu[j], os.path.join(output_path_real, img_name_real), normalize=True)\n",
        "\n",
        "            # Generate fake image batch with G\n",
        "            fake = netG(real_cpu)\n",
        "            output_fake_g, f2 = netD(fake)\n",
        "            output_real_g, f1 = netD(real_cpu)\n",
        "            imagenes, etiquetas = data  \n",
        "              \n",
        "            # Calcular predicciones\n",
        "            predicciones = torch.round(fake).squeeze()\n",
        "              \n",
        "            # Contar aciertos\n",
        "            #correctos += (predicciones == etiquetas).sum().item()\n",
        "            total += len(etiquetas)\n",
        "          \n",
        "            loss_g = loss_function(fake, real_cpu) + loss_function_penalty(output_fake_g, output_real_g)\n",
        "            \n",
        "            # Classify all fake batch with D\n",
        "\n",
        "    \n",
        "            #DISCRIMINADOR\n",
        "            x1,output_fake = netD(fake.detach())\n",
        "            x2,output_real = netD(real_cpu.detach())\n",
        "\n",
        "            imagenes, etiquetas = data  \n",
        "              \n",
        "            # Calcular predicciones\n",
        "            predicciones = torch.round(output_fake).squeeze()\n",
        "              \n",
        "            # Contar aciertos\n",
        "            #correctos += (predicciones == etiquetas).sum().item()\n",
        "            total += len(etiquetas)\n",
        "\n",
        "            #LABELS\n",
        "            b_size = real_cpu.size(0)\n",
        "            label_real = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "            label_fake = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
        "            # Calculate D's loss on the all-fake batch\n",
        "            loss_fake = criterion(output_fake.view(-1), label_fake)\n",
        "            loss_real = criterion(output_real.view(-1), label_real)\n",
        "            loss_dic_tr = (loss_fake + loss_real)*0.5\n",
        "            loss_total_disc += loss_dic_tr.item()\n",
        "\n",
        "            #label.fill_(fake_label)\n",
        "            \n",
        "            D_x = output_real.mean().item()\n",
        "            D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "            # Check how the generator is doing by saving G's output on fixed_noise\n",
        "            if (i == len(test_loader)-1):\n",
        "                with torch.no_grad():\n",
        "                    fake = netG(real_cpu).detach().cpu()\n",
        "                    img_list_test.append(fake)\n",
        "                    # Guardar las im√°genes generadas en archivos de imagen\n",
        "                    for j in range(fake.size(0)):\n",
        "                        img_name = \"generated_image_{}.png\".format(i*test_loader.batch_size + j)\n",
        "                        vutils.save_image(fake[j], os.path.join(output_path_generate, img_name), normalize=True)\n",
        "      \n",
        "  # Calcular precisi√≥n\n",
        "  precision = correctos / total\n",
        "  print(\"Precisi√≥n del generador: {:.4f}\".format(precision))  "
      ],
      "metadata": {
        "id": "wTsbwLsekYVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PARA QUE ESTOOOO?????????????????????\n",
        "\n",
        "if testing:\n",
        "  img_list_test = []\n",
        "\n",
        "  name_gen = 'GenModel_'+ str(num_epochs -1 ) +'.pth'\n",
        "  name_dis = 'DisModel_'+ str(num_epochs -1 ) +'.pth'\n",
        "  # Cargar los par√°metros de la red neuronal\n",
        "  \n",
        "  output_path = \"/content/drive/MyDrive/9 Semestre/Seminario de Tesisi/output/salidas\"\n",
        "  # output_path = \"/content/drive/MyDrive/UNIVERSIDAD 5TO/COSAS MIAS/GANS/DATASET/Originales2/output2/salidas\"\n",
        "\n",
        "\n",
        "  # Elimina la carpeta y crea una nueva\n",
        "  os.system(f'rm -rf {output_path}')\n",
        "  #os.mkdir(output_path)\n",
        "\n",
        "  # Evaluar el modelo en el conjunto de datos de prueba\n",
        "  netG.eval()\n",
        "  netD.eval()\n",
        "\n",
        "  correctos = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      \n",
        "        loss_total_disc = 0\n",
        "\n",
        "        # For each batch in the dataloader\n",
        "        for i, data in enumerate(test_loader, 0):\n",
        "            \n",
        "            real_cpu = data[0].to(device)\n",
        "\n",
        "            for j in range(real_cpu.size(0)):\n",
        "              # Save the real image\n",
        "              img_name_real = \"real_image_{}.png\".format(i*test_loader.batch_size + j)\n",
        "              vutils.save_image(real_cpu[j], os.path.join(output_path, img_name_real), normalize=True)\n",
        "\n",
        "            # Generate fake image batch with G\n",
        "            fake = netG(real_cpu).detach().cpu()\n",
        "\n",
        "            img_list_test.append(fake)\n",
        "            # Guardar las im√°genes generadas en archivos de imagen\n",
        "            for j in range(fake.size(0)):\n",
        "                img_name = \"generated_image_{}.png\".format(i*test_loader.batch_size + j)\n",
        "                vutils.save_image(fake[j], os.path.join(output_path, img_name), normalize=True)"
      ],
      "metadata": {
        "id": "ViZW7B-ze3zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if testing and comparation:\n",
        "  # Grab a batch of real images from the dataloader\n",
        "  real_batch = next(iter(test_loader))\n",
        "\n",
        "  # Plot the fake images from the last epoch\n",
        "  plt.figure(figsize=(30,30))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.axis(\"off\")\n",
        "  plt.title(\"TEST Images\")\n",
        "  plt.imshow(np.transpose(img_list_test[-1],(1,2,0)))\n",
        "  plt.show()\n",
        "  print(np.transpose(img_list_test[-1],(1,2,0)).size())"
      ],
      "metadata": {
        "id": "Qdt3Yn23r9CM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}